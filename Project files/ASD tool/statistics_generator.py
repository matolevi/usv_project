# -*- coding: utf-8 -*-
""" Statistics_generator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HGHVBg_4sJYWX4kh30RVxCuQtr3-XOtL
"""



import numpy as np
import PIL.Image as Image
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
import tensorflow_hub as hub
from tensorflow.keras.preprocessing import image
import pandas as pd
import os
import xlrd
import math
import scipy
import scipy.io.wavfile as wavfile
from scipy.signal import butter, lfilter, freqz
import librosa
import librosa.display
import cv2

def butter_highpass_filter(cutoff_H, fs, order):
  nyq = 0.5*fs
  normal_cutoff = cutoff_H/nyq
  b, a = butter(order, normal_cutoff, btype='high', analog=False)
  return a, b

class sample:
  def __init__(self, mother, name, sex, age, matgen, pupgen, rec_num, syls, time_between):
    self.mother = mother
    self.name = name
    self.sex = sex
    self.age = age
    self.matgen = matgen
    self.pupgen = pupgen
    self.rec_num = rec_num
    self.syls = syls
    self.time_between = time_between

def Syl_Class_Vec(model,age,matgen,pupgen,mother,name,sex,session,rec_num,start,finish):
  # Commented out IPython magic to ensure Python compatibility.

  fs = 250000
  order = 6
  cutoff_H = 30*10**3
  c, d = butter_highpass_filter(cutoff_H, fs, order)


  samples = []
  sr = 250000
  max_time = 0.25
  pred = []
  timeB = []
  time_diff = []
  start_arr = np.array(start) #converting to array
  finish_arr = np.array(finish)
  time_diff = np.subtract(finish_arr, start_arr) #calculating each syllable length
  for i in range(len(mother)):
    path = 'C:/Users/77sha/Desktop/USV Recording/2022/{}_{}/{}_{}/day_{}/session{}/{}.wav'.format(mother[i], matgen[i], name[i], pupgen[i], int(age[i]), int(session[i]), rec_num[i]) #find path of each recording
    if not os.path.exists('{}'.format(path)):
      path = 'C:/Users/77sha/Desktop/USV Recording/2022/{}_{}/{}_{}/day_{}/session{}/{}.WAV'.format(mother[i], matgen[i], name[i], pupgen[i], int(age[i]), int(session[i]), rec_num[i])
      if not os.path.exists('{}'.format(path)):
        print(i)
        continue
    if i>0 and (rec_num[i] != rec_num[i-1] or name[i] != name[i-1]):
      recording = sample(mother[i-1], name[i-1], sex[i-1], age[i-1], matgen[i-1], pupgen[i-1], rec_num[i-1], pred, timeB)
      samples.append(recording)
      pred = []
      timeB = []
    if time_diff[i] < max_time:
      rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs
      temp = (max_time - time_diff[i])/2
      silence = np.zeros(round((temp)*rate))
      trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel
      syl = np.append(silence, trimmed) #normalizing length to max syllable
      syl = np.append(syl, silence)
    else:
      rec, rate = librosa.load(path, sr)
      syl = rec[round((start[i])*rate):round((finish[i])*rate)]
    #pre processing
    syl = lfilter(d, c, syl) #hpf
    #STFT creation
    D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram
    D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood
    D = D - 0.02*np.mean(D)
    D = np.repeat(D[:, :, np.newaxis], 3, -1)
    D = D.astype('float32')
    D = D/255
    D = image.img_to_array(D)
    D = np.expand_dims(D, axis=0)
    predict = model.predict(D)
    pred.append(predict)
    if len(pred) > 1:
      timeB.append(start[i] - finish[i-1])

  samples = np.array(samples)
  return samples

