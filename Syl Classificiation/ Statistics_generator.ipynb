{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"עותק של Statistics_generator.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"NM5H6sZgJIf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655151563903,"user_tz":-180,"elapsed":23718,"user":{"displayName":"Shaked Weinberger","userId":"10173627776225637935"}},"outputId":"a35f9f08-8558-4fb3-dcec-1c4b1a797512"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/Shareddrives/USV_Project_2021/E:/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1ZAaPx3ZyueNJEhIpm0_6D9KpkprurC0K/E:\n"]}]},{"cell_type":"code","metadata":{"id":"z_HsDdz2JetD","executionInfo":{"status":"ok","timestamp":1655151572835,"user_tz":-180,"elapsed":8938,"user":{"displayName":"Shaked Weinberger","userId":"10173627776225637935"}}},"source":["import numpy as np\n","import PIL.Image as Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing import image\n","import pandas as pd\n","import os\n","import xlrd\n","import math\n","import scipy\n","import scipy.io.wavfile as wavfile\n","from scipy.signal import butter, lfilter, freqz\n","import librosa\n","import librosa.display\n","import cv2"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOO7o_Y7bsNO","executionInfo":{"status":"ok","timestamp":1655151596049,"user_tz":-180,"elapsed":294,"user":{"displayName":"Shaked Weinberger","userId":"10173627776225637935"}}},"source":["def butter_highpass_filter(cutoff_H, fs, order):\n","  nyq = 0.5*fs\n","  normal_cutoff = cutoff_H/nyq\n","  b, a = butter(order, normal_cutoff, btype='high', analog=False)\n","  return a, b\n","\n","class sample:\n","  def __init__(self, mother, name, sex, age, matgen, pupgen, rec_num, syls, time_between):\n","    self.mother = mother\n","    self.name = name\n","    self.sex = sex\n","    self.age = age\n","    self.matgen = matgen\n","    self.pupgen = pupgen\n","    self.rec_num = rec_num\n","    self.syls = syls\n","    self.time_between = time_between"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9TtpXXxJN9K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655151700735,"user_tz":-180,"elapsed":90315,"user":{"displayName":"Shaked Weinberger","userId":"10173627776225637935"}},"outputId":"ae354ba7-33c1-43f6-c047-f6a91f83cbb7"},"source":["model_path = '/content/drive/Shareddrives/USV_Project_2021/E:/model_weights.h6'\n","model = keras.models.load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer})\n","\n","fs = 250000\n","order = 6\n","cutoff_H = 30*10**3\n","c, d = butter_highpass_filter(cutoff_H, fs, order)\n","\n","%cd /content/drive/MyDrive/final_project/\n","data_table = xlrd.open_workbook('New Segmentatio Data For Final Class_1.xlsx').sheet_by_index(0)\n","age = data_table.col_values(6, 1)\n","matgen = data_table.col_values(2, 1)\n","pupgen = data_table.col_values(5, 1)\n","mother = data_table.col_values(1, 1)\n","name = data_table.col_values(3, 1)\n","sex = data_table.col_values(4, 1)\n","session = data_table.col_values(7, 1)\n","#syllable = data_table.col_values(14, 1)\n","rec_num = data_table.col_values(8, 1)\n","start = data_table.col_values(9, 1)\n","finish = data_table.col_values(10, 1)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n","/content/drive/MyDrive/final_project\n"]}]},{"cell_type":"code","metadata":{"id":"RFcti5PvNOG_","executionInfo":{"status":"ok","timestamp":1655166233123,"user_tz":-180,"elapsed":14524124,"user":{"displayName":"Shaked Weinberger","userId":"10173627776225637935"}}},"source":["samples = []\n","sr = 250000\n","max_time = 0.25\n","pred = []\n","timeB = []\n","time_diff = []\n","start_arr = np.array(start) #converting to array\n","finish_arr = np.array(finish)\n","time_diff = np.subtract(finish_arr, start_arr) #calculating each syllable length\n","for i in range(len(mother)):\n","  path = '/content/drive/MyDrive/USV Recordings/2022/{}_{}/{}_{}/day_{}/session{}/{}.wav'.format(mother[i], matgen[i], name[i], pupgen[i], int(age[i]), int(session[i]), rec_num[i]) #find path of each recording\n","  if not os.path.exists('{}'.format(path)):\n","    path = '/content/drive/MyDrive/USV Recordings/2022/{}_{}/{}_{}/day_{}/session{}/{}.WAV'.format(mother[i], matgen[i], name[i], pupgen[i], int(age[i]), int(session[i]), rec_num[i])\n","    if not os.path.exists('{}'.format(path)):\n","      print(i)\n","      continue\n","  if i>0 and (rec_num[i] != rec_num[i-1] or name[i] != name[i-1]):\n","    recording = sample(mother[i-1], name[i-1], sex[i-1], age[i-1], matgen[i-1], pupgen[i-1], rec_num[i-1], pred, timeB)\n","    samples.append(recording)\n","    pred = []\n","    timeB = []\n","  if time_diff[i] < max_time:\n","    rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs\n","    temp = (max_time - time_diff[i])/2\n","    silence = np.zeros(round((temp)*rate))\n","    trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel\n","    syl = np.append(silence, trimmed) #normalizing length to max syllable\n","    syl = np.append(syl, silence)\n","  else:\n","    rec, rate = librosa.load(path, sr)\n","    syl = rec[round((start[i])*rate):round((finish[i])*rate)]\n","  #pre processing\n","  syl = lfilter(d, c, syl) #hpf\n","  #STFT creation\n","  D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram\n","  D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood\n","  D = D - 0.02*np.mean(D)\n","  D = np.repeat(D[:, :, np.newaxis], 3, -1)\n","  D = D.astype('float32')\n","  D = D/255\n","  D = image.img_to_array(D)\n","  D = np.expand_dims(D, axis=0)\n","  predict = model.predict(D)\n","  pred.append(predict)\n","  if len(pred) > 1:\n","    timeB.append(start[i] - finish[i-1])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgXQUsSwNJyU","executionInfo":{"status":"ok","timestamp":1652200997068,"user_tz":-180,"elapsed":1151,"user":{"displayName":"Shaked Weinberger","userId":"10173627776225637935"}},"outputId":"75c54be0-43c2-40c6-84dc-c9436b0b2283"},"source":["print(samples[100].syls)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([[0.10424803, 0.02017718, 0.10995657, 0.04979197, 0.00645146,\n","        0.04784222, 0.00493989, 0.01105884, 0.63128066, 0.01425312]],\n","      dtype=float32), array([[1.4041255e-03, 9.1969721e-02, 1.5656819e-03, 9.0126616e-01,\n","        5.3496141e-04, 4.7518732e-04, 4.2291899e-04, 2.2549591e-04,\n","        1.6574243e-03, 4.7824337e-04]], dtype=float32), array([[0.01140546, 0.68735087, 0.0199605 , 0.24373047, 0.00204667,\n","        0.00183484, 0.00313926, 0.00193183, 0.02591688, 0.00268325]],\n","      dtype=float32)]\n"]}]},{"cell_type":"code","metadata":{"id":"8sR15xeE6H1X"},"source":["samples = np.array(samples)\n","np.save('model_prediction_recordings_New_3B.npy', samples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"id":"uEFjRXfoOmJd","executionInfo":{"status":"ok","timestamp":1628925566434,"user_tz":-180,"elapsed":65,"user":{"displayName":"Guy Lavy","photoUrl":"","userId":"17597021433543225927"}},"outputId":"0acf9fbe-5960-4cfe-cecd-09ea6e56bb9c"},"source":["'''\n","i = 731\n","pred = []\n","timeB = 1\n","sr = 250000 \n","time_diff = []\n","start_arr = np.array(start) #converting to array\n","finish_arr = np.array(finish)\n","time_diff = np.subtract(finish_arr, start_arr)\n","max_time = 0.25\n","path = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i])\n","if time_diff[i] < max_time:\n","  rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs\n","  temp = (max_time - time_diff[i])/2\n","  silence = np.zeros(round((temp)*rate))\n","  trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel\n","  syl = np.append(silence, trimmed) #normalizing length to max syllable\n","  syl = np.append(syl, silence)\n","else:\n","  rec, rate = librosa.load(path, sr)\n","  syl = rec[round((start[i])*rate):round((finish[i])*rate)]\n","#pre processing\n","syl = lfilter(d, c, syl) #hpf\n","\n","D = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram\n","D = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood\n","D = D - 0.02*np.mean(D)\n","fig, ax = plt.subplots(nrows=1, ncols=1)\n","ax.pcolormesh(20*np.log10(D))\n","D = np.repeat(D[:, :, np.newaxis], 3, -1)\n","D = D.astype('float32')\n","D = D/255\n","D = image.img_to_array(D)\n","D = np.expand_dims(D, axis=0)\n","predict = model.predict(D)\n","pred.append(predict)\n","pred.append(predict)\n","sample1 = sample(mother[i], name[i], sex[i], age[i], matgen[i], pupgen[i], rec_num[i], pred, timeB)\n","#pred = np.where(pred == np.max(pred))\n","print(sample1.syls)\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\ni = 731\\npred = []\\ntimeB = 1\\nsr = 250000 \\ntime_diff = []\\nstart_arr = np.array(start) #converting to array\\nfinish_arr = np.array(finish)\\ntime_diff = np.subtract(finish_arr, start_arr)\\nmax_time = 0.25\\npath = '/content/drive/Shareddrives/TEST_RECORDINGS/Final_Project/Recordings_ella_ayelet/total_data/{}/{}/{}.wav'.format(mother[i], name[i], rec_num[i])\\nif time_diff[i] < max_time:\\n  rec, rate = librosa.load(path, sr) #opens recordings and sample rate, add sample rate of USVs\\n  temp = (max_time - time_diff[i])/2\\n  silence = np.zeros(round((temp)*rate))\\n  trimmed = rec[round((start[i])*rate):round((finish[i])*rate)] #trimming the syllables according to start and fin poitns from excel\\n  syl = np.append(silence, trimmed) #normalizing length to max syllable\\n  syl = np.append(syl, silence)\\nelse:\\n  rec, rate = librosa.load(path, sr)\\n  syl = rec[round((start[i])*rate):round((finish[i])*rate)]\\n#pre processing\\nsyl = lfilter(d, c, syl) #hpf\\n\\nD = np.abs(librosa.stft(syl, n_fft=2048, hop_length=128, win_length=512, window='hamming')) #creating stft and using absolute value for spectrogram\\nD = cv2.resize(D, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #resizing the spectograms for usage in the model. INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood\\nD = D - 0.02*np.mean(D)\\nfig, ax = plt.subplots(nrows=1, ncols=1)\\nax.pcolormesh(20*np.log10(D))\\nD = np.repeat(D[:, :, np.newaxis], 3, -1)\\nD = D.astype('float32')\\nD = D/255\\nD = image.img_to_array(D)\\nD = np.expand_dims(D, axis=0)\\npredict = model.predict(D)\\npred.append(predict)\\npred.append(predict)\\nsample1 = sample(mother[i], name[i], sex[i], age[i], matgen[i], pupgen[i], rec_num[i], pred, timeB)\\n#pred = np.where(pred == np.max(pred))\\nprint(sample1.syls)\\n\""]},"metadata":{"tags":[]},"execution_count":8}]}]}